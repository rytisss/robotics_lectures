{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-17T23:14:03.365442Z",
     "iopub.status.busy": "2024-07-17T23:14:03.3646Z",
     "iopub.status.idle": "2024-07-17T23:14:03.373644Z",
     "shell.execute_reply": "2024-07-17T23:14:03.372101Z",
     "shell.execute_reply.started": "2024-07-17T23:14:03.3654Z"
    }
   },
   "source": [
    "# Based on code from https://www.kaggle.com/code/muhammadfaizan65/machine-failure-prediction-eda-modeling. Added new models and comparison. Data can be found here https://www.kaggle.com/datasets/umerrtx/machine-failure-prediction-using-sensor-data?resource=download. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "This dataset contains sensor data collected from various machines, to predict machine failures in advance. It includes a variety of sensor readings as well as recorded machine failures.\n",
    "\n",
    "# Columns Description\n",
    "footfall: The number of people or objects passing by the machine.  \n",
    "tempMode: The temperature mode or setting of the machine.  \n",
    "AQ: Air quality index near the machine.  \n",
    "USS: Ultrasonic sensor data, indicating proximity measurements.  \n",
    "CS: Current sensor readings, indicating the electrical current usage of the machine.  \n",
    "VOC: Volatile organic compounds level detected near the machine.  \n",
    "RP: Rotational position or RPM (revolutions per minute) of the machine parts.  \n",
    "IP: Input pressure to the machine.  \n",
    "Temperature: The operating temperature of the machine.  \n",
    "fail: Binary indicator of machine failure (1 for failure, 0 for no failure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"data.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info and summary\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numeric columns\n",
    "fig = make_subplots(rows=5, cols=2, subplot_titles=data.columns)\n",
    "for i, column in enumerate(data.columns):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    hist = px.histogram(data, x=column, template='plotly_dark', color_discrete_sequence=['#F63366'])\n",
    "    hist.update_traces(marker_line_width=0.5, marker_line_color=\"white\")\n",
    "    fig.add_trace(hist.data[0], row=row, col=col)\n",
    "\n",
    "fig.update_layout(height=1200, title_text=\"Distribution of Numeric Columns\", title_font=dict(size=25), title_x=0.5, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation Heatmap\n",
    "corr = data.corr()\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=corr.values,\n",
    "    x=list(corr.columns),\n",
    "    y=list(corr.index),\n",
    "    annotation_text=corr.round(2).values,\n",
    "    showscale=True,\n",
    "    colorscale='Viridis')\n",
    "fig.update_layout(title_text='Correlation Heatmap', title_font=dict(size=25), title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for each feature to identify outliers\n",
    "fig = make_subplots(rows=5, cols=2, subplot_titles=data.columns[:-1])\n",
    "for i, column in enumerate(data.columns[:-1]):  # Excluding the target column 'fail'\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    box = px.box(data, y=column, template='plotly_dark', color_discrete_sequence=['#636EFA'])\n",
    "    box.update_traces(marker_line_width=0.5, marker_line_color=\"white\")\n",
    "    fig.add_trace(box.data[0], row=row, col=col)\n",
    "\n",
    "fig.update_layout(height=1200, title_text=\"Boxplots of Features\", title_font=dict(size=25), title_x=0.5, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots to visualize relationships between features and target\n",
    "fig = make_subplots(rows=5, cols=2, subplot_titles=data.columns[:-1])\n",
    "for i, column in enumerate(data.columns[:-1]):  # Excluding the target column 'fail'\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    scatter = px.scatter(data, x=column, y='fail', template='plotly_dark', color='fail', color_continuous_scale='Viridis')\n",
    "    scatter.update_traces(marker=dict(size=5, opacity=0.7, line=dict(width=0.5, color='white')))\n",
    "    fig.add_trace(scatter.data[0], row=row, col=col)\n",
    "\n",
    "fig.update_layout(height=1200, title_text=\"Scatter Plots of Features vs Fail\", title_font=dict(size=25), title_x=0.5, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X = data.drop(columns=['fail'])\n",
    "y = data['fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Hyperparameter Tuning\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'GradientBoosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    'LogisticRegression': {'C': [0.01, 0.1, 1, 10]},\n",
    "    'SVM': {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "best_accuracy = 0\n",
    "best_model_name = ''\n",
    "best_model = None\n",
    "\n",
    "for model_name in models.keys():\n",
    "    grid = GridSearchCV(models[model_name], params[model_name], cv=5, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid.best_params_}\")\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {model_name}: {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = model_name\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot confusion matrix\n",
    "fig = px.imshow(cm, text_auto=True, color_continuous_scale='Blues', template='plotly_dark')\n",
    "fig.update_layout(title_text=f'Confusion Matrix for {best_model_name}', title_font=dict(size=25), title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(f'Classification Report for {best_model_name}')\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC for the best model\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'{best_model_name} (AUC = {roc_auc:.2f})', line=dict(width=2)))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash', color='gray'), name='Random'))\n",
    "fig.update_layout(title_text='Receiver Operating Characteristic', title_font=dict(size=25), xaxis_title='False Positive Rate', yaxis_title='True Positive Rate', template='plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "The ROC curve displayed above shows the performance of the **RandomForest** classifier on the test dataset. The curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **True Positive Rate (TPR)**: Also known as Sensitivity or Recall, it is the ratio of correctly predicted positive observations to the actual positives.\n",
    "- **False Positive Rate (FPR)**: It is the ratio of incorrectly predicted positive observations to the actual negatives.\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "- A perfect classifier would have an AUC of **1.0**, while a classifier with no discriminative power would have an AUC of **0.5** (represented by the dashed line labeled \"Random\").\n",
    "- The ROC curve is very close to the top left corner, demonstrating that the model has a high TPR and a low FPR, meaning it correctly identifies a large proportion of positive cases while keeping false positives to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5280683,
     "sourceId": 8784285,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
